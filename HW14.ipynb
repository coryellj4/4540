{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coryellj4/4540/blob/main/HW14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBGwMsiQMQbp"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cyneuro/Neural-Networks-Machine-Learning/blob/master/CNN/Convolutional_Neural_Network_time_series.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G6nkn3IlMQbt"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels: int = 1,\n",
        "                 hidden_dims: List = None,\n",
        "                 output_length: int = 2) -> None:\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        if hidden_dims is None:\n",
        "            hidden_dims = [32, 64, 128, 64, 32, 1]\n",
        "\n",
        "        modules = []\n",
        "\n",
        "        for h_dim in hidden_dims:\n",
        "            modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv1d(in_channels, out_channels=h_dim,\n",
        "                              kernel_size=3, stride=2, padding=1),\n",
        "                    nn.BatchNorm1d(h_dim),\n",
        "                    nn.ReLU())\n",
        "            )\n",
        "            in_channels = h_dim\n",
        "\n",
        "        self.forward_net = nn.Sequential(*modules)\n",
        "\n",
        "        self.fcfinal = nn.Linear(4, output_length)\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.forward_net(x)\n",
        "        out = self.fcfinal(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "w6QAlGvvMQbu"
      },
      "source": [
        "## Data Generation\n",
        "\n",
        "Here we start to generate data. If you intend to use your own data skip the next 4 code blocks. This data is a set of sine waves at 100 Hz combined with pink noise from the colorednoise python library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sX2HjViiMQbu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "frequency = 100\n",
        "\n",
        "samples = 2**8\n",
        "\n",
        "t = np.linspace(0, 1, samples)\n",
        "sine = 0.1 * np.sin(frequency * 2 * np.pi * t)\n",
        "print(sine.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kD2I7auqMQbv"
      },
      "outputs": [],
      "source": [
        "!pip install colorednoise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CSAkJIcgMQbw"
      },
      "source": [
        "#### Combined Noise and Signal\n",
        "\n",
        "As can be seen in the graph below, the pure pink noise signal and the combined pink noise and sine signal is hardly distinguishable by the human eye. A CNN can make the distinction however."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mO3jCjX8MQbw"
      },
      "outputs": [],
      "source": [
        "import colorednoise as cn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "beta = 1  # pink noise is 1\n",
        "\n",
        "noise = cn.powerlaw_psd_gaussian(beta, samples)\n",
        "plt.plot(noise, label='Noise')\n",
        "plt.plot(noise+sine, label='Noise and Signal')\n",
        "plt.title('Colored Noise for Î²='+str(beta))\n",
        "plt.xlabel('Samples (time-steps)')\n",
        "plt.ylabel('Amplitude(t)', fontsize='large')\n",
        "plt.xlim(1,samples)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "HxAvo3d6MQbx"
      },
      "source": [
        "#### Building the Dataset\n",
        "\n",
        "This is when we finally build the dataset. Note we specify the number of samples and let the code determine if the data contains a sine wave or not. This is done through a random choice so that we get a balanced dataset with roughly half the samples containing the sine wave and the other half as pure pink noise. Overall, the input data becomes 10000 samples of a single signal for 256 timesteps. The output is 10000 samples for 1 signal of 2 choices (Contains or Does not Contain a sine wave)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "B356yAN4MQby"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "labels = []\n",
        "num_samples = 10000\n",
        "for i in range(num_samples):\n",
        "    if np.random.randint(low=0.0, high=2.0):\n",
        "        data.append(cn.powerlaw_psd_gaussian(beta, samples))\n",
        "        labels.append([1,0])\n",
        "    else:\n",
        "        data.append(cn.powerlaw_psd_gaussian(beta, samples) + sine)\n",
        "        labels.append([0,1])\n",
        "\n",
        "data = np.stack(data).reshape((num_samples, 1, -1))\n",
        "labels = np.stack(labels).reshape((num_samples, 1, -1))\n",
        "print(data.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "31X7CRUnMQby"
      },
      "source": [
        "#### DataLoaders\n",
        "\n",
        "DataLoaders are a feature of PyTorch meant to make training easier. Below we just simply split the data to be a 75% training 25% validation split and pass them to the DataLoader with the batch size and whether or not to shuffle the data. Now we are ready to look at training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ey0W4SzEMQbz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "split_idx = int(.75 * data.shape[0])\n",
        "\n",
        "print(split_idx)\n",
        "print(data.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "train_data = DataLoader(TensorDataset(torch.Tensor(data[:split_idx, :, :]), torch.Tensor(labels[:split_idx, :, :])), batch_size=batch_size, shuffle=True)\n",
        "valid_data = DataLoader(TensorDataset(torch.Tensor(data[split_idx:, :, :]), torch.Tensor(labels[split_idx:, :, :])), batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "dWmZioNQMQb0"
      },
      "source": [
        "#### Training\n",
        "\n",
        "This is an example of a training loop. Notice it takes both validation and training into account. While this is not necessary, we do it just so we can run both in parallel and maximize our efficiency.\n",
        "\n",
        "The key lines here are:\n",
        "```python\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "```\n",
        "and this is what allows for training. If you notice, these are only called when using a training dataset because these two lines are the actual backpropagation and updates of the weights in the network. If these lines are not called the network does not learn. The rest is basically built around trying to help the net learn easier (updatable learning rates, loss printing, tqdm, etc.)\n",
        "\n",
        "*If you want to change the loss function* take a look at the line that says:\n",
        "```python\n",
        "loss_func = nn.MSELoss() if 'loss_function' not in kwargs else kwargs.get('loss_function')\n",
        "```\n",
        "This basically means we can specify a loss function to the fit function call, or if you want simply change the function from Mean Squared Error here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Xf-B408TMQb0"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Tuple\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "def fit(model: nn.Module,\n",
        "        training_loader: DataLoader,\n",
        "        validation_loader: DataLoader,\n",
        "        epochs: int = 50,\n",
        "        device: str = 'cpu',\n",
        "        write_losses: bool = False,\n",
        "        save_filepath: Optional[str] = None,\n",
        "        **kwargs) -> Tuple[List, List]:\n",
        "    \"\"\"\n",
        "    Function used to fit the specified model with the provided data\n",
        "    :param model: neural network pytorch model\n",
        "    :param training_loader: pytorch dataloader containing the training data\n",
        "    :param validation_loader: pytorch dataloader containing the validation data\n",
        "    :param epochs: number of epochs to train\n",
        "    :param device: which device to train the model on. Should be either \"cuda:0\" or \"cpu\"\n",
        "    :param write_losses: boolean flag as to report losses during training\n",
        "    :param save_filepath: path to save model, if not specified, no model is saved\n",
        "    :param kwargs: \"optim\" optimizer,\n",
        "                    \"loss_function\" loss function,\n",
        "                    \"decay_rate\" decay rate,\n",
        "                    \"model_save_path\" model save path,\n",
        "                    \"loss_save_path\" csv save path\n",
        "    :return: training and validation losses over each epoch\n",
        "    \"\"\"\n",
        "    train_loss_list = []\n",
        "    val_loss_list = []\n",
        "\n",
        "    # splitting the dataloaders to generalize code\n",
        "    data_loaders = {\"train\": training_loader, \"val\": validation_loader}\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005) if 'optim' not in kwargs else kwargs.get('optim')\n",
        "\n",
        "    loss_func = nn.MSELoss() if 'loss_function' not in kwargs else kwargs.get('loss_function')\n",
        "\n",
        "    decay_rate = .99995 if 'decay_rate' not in kwargs else kwargs.get('decay_rate')\n",
        "    lr_sch = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate)\n",
        "\n",
        "    temp_loss = 100000000000000.0\n",
        "\n",
        "    \"\"\"\n",
        "    You can easily adjust the number of epochs trained here by changing the number in the range\n",
        "    \"\"\"\n",
        "    for epoch in tqdm(range(epochs), position=0, leave=True):\n",
        "        train_loss = 0.0\n",
        "        val_loss = 0.0\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)\n",
        "            else:\n",
        "                model.train(False)\n",
        "\n",
        "            running_loss = 0.0\n",
        "            for i, (x, y) in enumerate(data_loaders[phase]):\n",
        "                x = x.to(device)\n",
        "                output = model(x)\n",
        "                y = y.to(device)\n",
        "                loss = loss_func(torch.squeeze(output), torch.squeeze(y))\n",
        "\n",
        "                # backprop\n",
        "                optimizer.zero_grad()\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # calculating total loss\n",
        "                running_loss += loss.item()\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss = running_loss\n",
        "                lr_sch.step()\n",
        "            else:\n",
        "                val_loss = running_loss\n",
        "\n",
        "        # shows total loss\n",
        "        if epoch % 10 == 0 and write_losses:\n",
        "            tqdm.write('{} train loss: {.6f} val loss: {.6f}'.format(epoch + 1, train_loss, val_loss))\n",
        "\n",
        "        # saving best model\n",
        "        if train_loss < temp_loss and save_filepath:\n",
        "            torch.save(model, save_filepath)\n",
        "            temp_loss = train_loss\n",
        "\n",
        "        train_loss_list.append(train_loss)\n",
        "        val_loss_list.append(val_loss)\n",
        "\n",
        "\n",
        "    return train_loss_list, val_loss_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "in76yA_wMQb2"
      },
      "source": [
        "#### Running the Model\n",
        "\n",
        "Here its pretty straightforward, simply pass the model, dataloaders, number of epochs, and device to the fit function. We also specify a loss function just to show how it can be done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VXionII_MQb3"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "epochs = 100\n",
        "model = ConvNet()\n",
        "model_initial = copy.deepcopy(model)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "t_loss, v_loss = fit(model, train_data, valid_data, epochs, device, loss_function=nn.BCEWithLogitsLoss())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "PVgAzzW5MQb4"
      },
      "source": [
        "#### Validation\n",
        "\n",
        "Here we just calculate the results of the validation training dataset to show it in a confusion matrix. Since we are calculating a Binary True/False problem a confusion matrix works perfectly to show how well the model is working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "koF2wuBBMQb4"
      },
      "outputs": [],
      "source": [
        "def validate_model(model: nn.Module,\n",
        "                   validation_loader: torch.utils.data.DataLoader,\n",
        "                   device: torch.device) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    output_list = None\n",
        "    y_list = None\n",
        "    for i, (x, y) in enumerate(validation_loader):\n",
        "        x = x.to(device)\n",
        "        output = model(x)\n",
        "        if i == 0:\n",
        "            output_list = output.to(\"cpu\").detach().numpy()\n",
        "            y_list = y.to(\"cpu\").detach().numpy()\n",
        "        else:\n",
        "            output_list = np.append(output_list, output.to(\"cpu\").detach().numpy(), axis=0)\n",
        "            y_list = np.append(y_list, y.to(\"cpu\").detach().numpy(), axis=0)\n",
        "    return np.squeeze(np.argmax(output_list, axis=2)), np.squeeze(np.argmax(y_list, axis=2))\n",
        "\n",
        "\n",
        "preds, labels = validate_model(model, valid_data, device)\n",
        "print(preds.shape, labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oVfNORuzMQb4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(labels, preds, display_labels=['No Sine', 'Sine'], cmap='cividis')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RNsVMSuoMQb5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NME",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}